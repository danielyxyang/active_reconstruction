{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments for \"Simplified 2D Setting\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Notebook\n",
    "\n",
    "Before running this interactive notebook, check the following parameters:\n",
    "- `ENV`: Select your execution environment `\"LOCAL\"` (VS Code, Jupyter Notebook) or `\"COLAB\"` (Google Colab).\n",
    "- `PLT_INTERACTIVE`: Select whether the plots should be interactive to allow zooming, panning and resizing. In general, this can stay activated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title { display-mode: \"form\" }\n",
    "\n",
    "ENV = \"LOCAL\" #@param [\"LOCAL\", \"COLAB\"]\n",
    "PLT_INTERACTIVE = True #@param {type:\"boolean\"}\n",
    "\n",
    "# setup environment\n",
    "LOCAL = \"LOCAL\"\n",
    "COLAB = \"COLAB\"\n",
    "if ENV == COLAB:\n",
    "    %cd /content\n",
    "    !git clone https://github.com/danielyxyang/active_reconstruction.git\n",
    "    %cd active_reconstruction\n",
    "    !git submodule update --init\n",
    "    %pip install -q -r requirements.txt\n",
    "    %pip install -q -r src/utils_ext/requirements.txt\n",
    "    %cd src\n",
    "elif ENV == LOCAL:\n",
    "    %cd ../src\n",
    "\n",
    "# setup interactive plots\n",
    "if PLT_INTERACTIVE:\n",
    "    if ENV == COLAB:\n",
    "        from google.colab import output\n",
    "        output.enable_custom_widget_manager()\n",
    "    %matplotlib widget\n",
    "else:\n",
    "    %matplotlib inline\n",
    "\n",
    "# ensure automatic reload of imported modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "### CUSTOM SETUP ###\n",
    "\n",
    "if ENV == COLAB:\n",
    "    # requiring disabled custom widget manager and ipywidgets 7.* to correctly\n",
    "    # display Tab widget in COLAB, changes to code marked with FIX\n",
    "    # https://github.com/googlecolab/colabtools/issues/3105\n",
    "    # https://github.com/googlecolab/colabtools/issues/3571\n",
    "    %pip install -q \"ipywidgets==7.*\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import parameters as params\n",
    "from algorithms.algorithms import ALGORITHMS, TRUE_ALGORITHM\n",
    "from simulation.plotter import SimulationPlotter, ALGORITHM_COLORS\n",
    "from simulation.simulation import Simulation, SimulationResults\n",
    "from simulation.camera import Camera\n",
    "from simulation.objects import Object, EllipseObject, SquareObject, FlowerObject, PolygonObject\n",
    "from utils.widgets import KernelSelector, ObjectSelector\n",
    "from utils_ext.tools import Profiler, build_json_encoder\n",
    "from utils_ext.widgets import build_widget_outputs\n",
    "\n",
    "plt.ioff() # prevent figures to be displayed without calling plt.show() or display()\n",
    "SimulationPlotter.set_interactive(PLT_INTERACTIVE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Setting\n",
    "\n",
    "Optionally, change the parameters of the simplified 2D setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title { display-mode: \"form\" }\n",
    "\n",
    "#@markdown *All values are specified in `[m]` except for `CAM_FOV`, which is specified in `[deg]`.*\n",
    "\n",
    "#@markdown world\n",
    "params.GRID_H = 0.1 # @param {type:\"slider\", min:0.05, max:1, step:0.05}\n",
    "\n",
    "#@markdown object\n",
    "params.OBJ_D_MAX = 8 #@param {type:\"number\"}\n",
    "params.OBJ_D_MIN = 2 #@param {type:\"number\"}\n",
    "\n",
    "#@markdown camera\n",
    "params.CAM_D = 10 #@param {type:\"number\"} \n",
    "params.CAM_DOF = 10 #@param {type:\"number\"}\n",
    "params.CAM_FOV = 35  #@param {type:\"number\"}\n",
    "params.OBS_NOISE = 0.2 #@param {type:\"slider\", min:0, max:5, step:0.1}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title { display-mode: \"form\" }\n",
    "\n",
    "if PLT_INTERACTIVE and ENV == COLAB:\n",
    "    # hack for displaying toolbar of interactive plots in Colab\n",
    "    html_hack = widgets.HTML(\"<style> .jupyter-matplotlib-figure { position: relative; } </style>\")\n",
    "    display(html_hack)\n",
    "\n",
    "def run_evaluation():\n",
    "\n",
    "    ### DEFINE PARAMETERS ###\n",
    "\n",
    "    REC_THRESH = 0.95\n",
    "    OUTPUT = os.path.join(\".\", \"..\", \"output\", \"experiments\")\n",
    "    \n",
    "    # define metrics\n",
    "    M_RANK = \"#\"\n",
    "    M_REC = \"reconstruction\"\n",
    "    M_MIS = \"missing\"\n",
    "    M_MEA = \"measurements\"\n",
    "    M_MEA_THRESH = \"measurements{:.0f}\".format(REC_THRESH * 100)\n",
    "    M_REG_AVG = \"average regret\"\n",
    "    M_REG_MAX = \"max regret\"\n",
    "    M_REG_MIN = \"min regret\"\n",
    "    metrics_f = {\n",
    "        M_REC:        lambda results: results.n_total_final_rel,\n",
    "        M_MIS:        lambda results: results.n_remaining,\n",
    "        M_MEA:        lambda results: results.n_measurements,\n",
    "        M_MEA_THRESH: lambda results: results.n_measurements_upto_thresh(REC_THRESH),\n",
    "        M_REG_AVG:    lambda results: results.regret_avg,\n",
    "        M_REG_MAX:    lambda results: results.regret_max,\n",
    "        M_REG_MIN:    lambda results: results.regret_min,\n",
    "    }\n",
    "    metrics_abbrev = {\n",
    "        M_REC:        \"rec\",\n",
    "        M_MIS:        \"miss\",\n",
    "        M_MEA:        \"mea\",\n",
    "        M_MEA_THRESH: \"mea{:.0f}\".format(REC_THRESH * 100),\n",
    "        M_REG_AVG:    \"reg\",\n",
    "        M_REG_MAX:    \"max reg\",\n",
    "        M_REG_MIN:    \"min reg\",\n",
    "    }\n",
    "    # define ranking\n",
    "    DESC = -1\n",
    "    ASC = 1\n",
    "    ranking = [\n",
    "        # (M_REG_AVG, ASC), # uncomment to order by regret\n",
    "        (M_MEA_THRESH, ASC),\n",
    "        (M_MEA, ASC),\n",
    "        (M_REC, DESC),\n",
    "    ]\n",
    "\n",
    "    ### DEFINE FUNCTIONS ###\n",
    "\n",
    "    def metric_from_result(object, algorithm, metric):\n",
    "        if algorithm in results[object]:\n",
    "            result = results[object][algorithm]\n",
    "            return metrics_f[metric](result)\n",
    "        else:\n",
    "            return np.nan\n",
    "    \n",
    "    def compute():\n",
    "        # display progress bars\n",
    "        with out[\"progressbar\"]:\n",
    "            clear_output(wait=True)\n",
    "            tqdm_objects = tqdm(total=len(selected[\"objects\"]), desc=\"Objects\", bar_format=\"{desc} |{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}{postfix}]\", leave=True)\n",
    "            tqdm_algorithms = tqdm(total=len(selected[\"algorithms\"]), desc=\"Algorithms\", bar_format=\"{desc} |{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}{postfix}]\", leave=True)\n",
    "            tqdm_steps = tqdm(total=100, unit=\"%\", desc=\"Simulation\", bar_format=\"{desc} |{bar}| {n:.1f}{unit} [{elapsed}<{remaining}{postfix}]\", leave=False)\n",
    "        \n",
    "        # run simulations for all selected algorithms and objects\n",
    "        with profiler.cm(\"computation\"):\n",
    "            # loop over objects\n",
    "            for object in selected[\"objects\"]:\n",
    "                tqdm_objects.set_postfix(object=object)\n",
    "                # loop over algorithms\n",
    "                tqdm_algorithms.reset()\n",
    "                for algorithm in selected[\"algorithms\"]:\n",
    "                    tqdm_algorithms.set_postfix(algorithm=algorithm)\n",
    "                    # initialize simulation\n",
    "                    simulation = Simulation.build(\n",
    "                        object=object,\n",
    "                        camera=Camera(),\n",
    "                        kernel=selected[\"kernel\"],\n",
    "                        algorithm=algorithm,\n",
    "                    )\n",
    "                    # run simulation\n",
    "                    tqdm_steps.reset()\n",
    "                    while not simulation.is_converged():\n",
    "                        tqdm_steps.set_postfix(iteration=len(simulation.n_marginal) + 1)\n",
    "                        simulation.step()\n",
    "                        # update progress bar\n",
    "                        tqdm_steps.update(simulation.progress() * 100 - tqdm_steps.n)\n",
    "                    results[object][algorithm] = simulation.results()\n",
    "                    plot_results(objects=[object])\n",
    "                    # update progress bar\n",
    "                    tqdm_algorithms.update(1)\n",
    "                # update progress bar\n",
    "                tqdm_objects.update(1)\n",
    "            # complete progress bar such that it disappears in case of incomplete reconstruction\n",
    "            tqdm_steps.update(tqdm_steps.total - tqdm_steps.n)\n",
    "            tqdm_steps.close()\n",
    "            tqdm_algorithms.close()\n",
    "            tqdm_objects.close()\n",
    "    \n",
    "    def compute_rankings():\n",
    "        with profiler.cm(\"computation\"):\n",
    "            # compute table data for rankings\n",
    "            metrics_ranking = [M_MEA_THRESH, M_MEA, M_REC, M_MIS, M_REG_AVG, M_REG_MAX] # M_RANK automatically included\n",
    "            df_rankings = {}\n",
    "            rank_columns, rank_order = zip(*ranking)\n",
    "            for object in selected[\"objects\"]:\n",
    "                df_ranking = pd.DataFrame({\n",
    "                    metric: {\n",
    "                        algorithm: metric_from_result(object, algorithm, metric)\n",
    "                        for algorithm in selected[\"algorithms\"] # index\n",
    "                    }\n",
    "                    for metric in metrics_ranking # columns\n",
    "                })\n",
    "                df_ranking[M_RANK] = (df_ranking\n",
    "                    .apply(\n",
    "                        lambda cols: tuple(cols[list(rank_columns)] * list(rank_order)) # turn columns into comparable tuples based on order\n",
    "                            # remove missing results or reconstruction below threshold\n",
    "                            if cols.notna().any() and cols[M_REC] >= REC_THRESH\n",
    "                            else np.nan,\n",
    "                        axis=1,\n",
    "                    )\n",
    "                    .rank(method=\"dense\") # rank without gaps\n",
    "                )\n",
    "                df_rankings[object] = df_ranking\n",
    "            results[\"_rankings\"] = df_rankings\n",
    "\n",
    "            # compute table data for summary\n",
    "            metrics_summary = [M_MEA_THRESH, M_MEA, M_REC, M_REG_AVG] # M_RANK automatically included\n",
    "            metrics_summary_avg = [M_MEA_THRESH, M_MEA, M_REC, M_REG_AVG] # M_RANK automatically included\n",
    "            df_summary = pd.DataFrame({\n",
    "                (object, metric): {\n",
    "                    algorithm: metric_from_result(object, algorithm, metric) if metric != M_RANK else df_rankings[object].loc[algorithm, M_RANK]\n",
    "                    for algorithm in selected[\"algorithms\"] # index\n",
    "                }\n",
    "                for object in selected[\"objects\"] # columns level 0 (outer loop)\n",
    "                for metric in [M_RANK] + metrics_summary # columns level 1 (inner loop)\n",
    "            })\n",
    "            if len(df_rankings) > 0:\n",
    "                # compute average metrics to summarize summary\n",
    "                avg_ranking = df_summary.loc[:, pd.IndexSlice[:, M_RANK]].mean(axis=1)\n",
    "                df_summary.insert(0, (\"avg\", M_RANK), avg_ranking)\n",
    "                for i, metric in enumerate(metrics_summary_avg, start=1):\n",
    "                    if metric == M_MEA or metric == M_MEA_THRESH:\n",
    "                        # compute number of measurements relative to optimal number of measurements\n",
    "                        n_measurements = df_summary.loc[:, pd.IndexSlice[:, metric]]\n",
    "                        n_measurements_opt = df_summary.loc[TRUE_ALGORITHM, pd.IndexSlice[:, metric]]\n",
    "                        avg_metric = (n_measurements / n_measurements_opt).mean(axis=1)\n",
    "                    else:\n",
    "                        avg_metric = df_summary.loc[:, pd.IndexSlice[:, metric]].mean(axis=1)\n",
    "                    df_summary.insert(i, (\"avg\", metric), avg_metric)\n",
    "            results[\"_summary\"] = df_summary\n",
    "\n",
    "    def plot_results(objects=None):\n",
    "        if objects is None:\n",
    "            objects = selected[\"objects\"]\n",
    "\n",
    "        with profiler.cm(\"plotting\"):\n",
    "            compute_rankings()\n",
    "            plot_summary()\n",
    "            for object in objects:\n",
    "                plot_object_results(object)\n",
    "\n",
    "        with out[\"log\"]:\n",
    "            clear_output(wait=True)\n",
    "            # print profiling\n",
    "            profiler.print([\"initialization\", \"computation\", \"plotting\", \"display\"])\n",
    "    \n",
    "    def plot_summary():\n",
    "        def highlight_metrics(df, style, where):\n",
    "            df_style = pd.DataFrame(\"\", index=df.index, columns=df.columns)\n",
    "            for object, algorithm in where:\n",
    "                for metric in df[[object]].columns.get_level_values(1):\n",
    "                    df_style.loc[algorithm, (object, metric)] = style\n",
    "            return df_style\n",
    "        \n",
    "        df_summary = results[\"_summary\"]\n",
    "        if len(df_summary) > 0:\n",
    "            df_summary = df_summary.sort_values(\n",
    "                by=[(\"avg\", M_RANK)] + [(\"avg\", metric) for metric, _ in ranking],\n",
    "                ascending=[True] + [metric_order == ASC for _, metric_order in ranking],\n",
    "            )\n",
    "        # apply style\n",
    "        df_summary_style = df_summary.style\n",
    "        if len(df_summary) > 0:\n",
    "            # left-align and color algorithm names\n",
    "            df_summary_style.applymap_index(lambda index: \"text-align: left;\", axis=\"index\")\n",
    "            df_summary_style.applymap_index(lambda index: \"color: {};\".format(ALGORITHM_COLORS[index]), axis=\"index\")\n",
    "            # highlight rankings\n",
    "            df_summary_style.applymap(lambda value: \"font-weight: bold;\", subset=pd.IndexSlice[:, pd.IndexSlice[:, M_RANK]])\n",
    "            # highlight TRUE_ALGORITHM\n",
    "            index_true = list(filter(lambda algorithm: algorithm == TRUE_ALGORITHM, selected[\"algorithms\"]))\n",
    "            df_summary_style.applymap_index(lambda index: \"background-color: rgba(175, 80, 80, 0.25);\" if index in index_true else None, axis=\"index\")\n",
    "            df_summary_style.applymap(lambda value: \"background-color: rgba(175, 80, 80, 0.25);\", subset=(index_true, df_summary.columns))\n",
    "            # highlight best reconstructions\n",
    "            cells_top = [(object, algorithm) \n",
    "                for object in selected[\"objects\"] for algorithm in selected[\"algorithms\"]\n",
    "                if df_summary.loc[algorithm, (object, M_RANK)] == 1\n",
    "            ]\n",
    "            df_summary_style.apply(lambda df: highlight_metrics(df, \"color: green\", cells_top), axis=None)\n",
    "            # gray out incomplete reconstructions\n",
    "            cells_incomplete = [(object, algorithm) \n",
    "                for object in selected[\"objects\"] for algorithm in selected[\"algorithms\"]\n",
    "                if df_summary.loc[algorithm, (object, M_REC)] < REC_THRESH\n",
    "            ]\n",
    "            df_summary_style.apply(lambda df: highlight_metrics(df, \"color: darkgray\", cells_incomplete), axis=None)\n",
    "            # gray out algorithms to be hidden\n",
    "            index_hide = list(filter(lambda algorithm: algorithm not in select_show_algorithms.value, selected[\"algorithms\"]))\n",
    "            df_summary_style.applymap_index(lambda index: \"color: darkgray;\" if index in index_hide else None, axis=\"index\")\n",
    "            df_summary_style.applymap(lambda value: \"color: darkgray;\", subset=(index_hide, df_summary.columns))\n",
    "            # gray out not yet computed results\n",
    "            df_summary_style.applymap(lambda value: \"color: darkgray;\" if np.isnan(value) else None)\n",
    "            # format values\n",
    "            df_summary_style.format(\"{:.0%}\", na_rep=\"N/A\", subset=pd.IndexSlice[:, pd.IndexSlice[:, M_REC]])\n",
    "            df_summary_style.format(precision=0, na_rep=\"N/A\", subset=pd.IndexSlice[:, pd.IndexSlice[:, [M_RANK, M_MEA, M_MEA_THRESH]]])\n",
    "            df_summary_style.format(precision=2, na_rep=\"N/A\", subset=pd.IndexSlice[:, pd.IndexSlice[:, M_REG_AVG]])\n",
    "            # format values differently in avg\n",
    "            df_summary_style.format(precision=1, na_rep=\"N/A\", subset=pd.IndexSlice[:, pd.IndexSlice[\"avg\", M_RANK]])\n",
    "            df_summary_style.format(\"{:.0%}\", na_rep=\"N/A\", subset=pd.IndexSlice[:, pd.IndexSlice[\"avg\", [M_MEA, M_MEA_THRESH]]])\n",
    "            # abbreviate metric names\n",
    "            df_summary_style.format_index(lambda metric: metrics_abbrev.get(metric, metric), axis=\"columns\", level=1)\n",
    "\n",
    "            results[\"_summary_style\"] = df_summary_style\n",
    "\n",
    "        with profiler.cm(\"display\"):\n",
    "            with out[\"tab_summary\"]:\n",
    "                display(df_summary_style, clear=True)\n",
    "\n",
    "    def plot_object_results(object):\n",
    "        results_obj = results[object]\n",
    "        df_ranking = results[\"_rankings\"][object]\n",
    "        plt_object = plotters[object][\"plt_object\"]\n",
    "        plt_total = plotters[object][\"plt_total\"]\n",
    "        plt_marginal = plotters[object][\"plt_marginal\"]\n",
    "        plt_regret = plotters[object][\"plt_regret\"]\n",
    "        out_obj = plotters[object][\"out\"]\n",
    "\n",
    "        df_ranking = (df_ranking\n",
    "            .reset_index(names=\"algorithm\") # make algorithm names to column\n",
    "            .reindex(columns=[M_RANK, \"algorithm\", *df_ranking.columns.drop(M_RANK)]) # place ranking column first\n",
    "            .sort_values(by=M_RANK)\n",
    "        )\n",
    "        # apply style\n",
    "        df_ranking_style = df_ranking.style\n",
    "        df_ranking_style.hide(axis=\"index\")\n",
    "        # left-align and color algorithm names\n",
    "        df_ranking_style.applymap_index(lambda index: \"text-align: left;\" if index == \"algorithm\" else None, axis=\"columns\")\n",
    "        df_ranking_style.applymap(lambda value: \"text-align: left;\", subset=\"algorithm\")\n",
    "        df_ranking_style.applymap(lambda value: \"color: {};\".format(ALGORITHM_COLORS[value]), subset=\"algorithm\")\n",
    "        # highlight TRUE_ALGORITHM\n",
    "        index_true = df_ranking.index[df_ranking[\"algorithm\"] == TRUE_ALGORITHM]\n",
    "        df_ranking_style.applymap(lambda value: \"background-color: rgba(175, 80, 80, 0.25);\", subset=(index_true, df_ranking.columns))\n",
    "        # gray out incomplete reconstructions\n",
    "        index_incomplete = df_ranking.index[df_ranking[M_REC] < REC_THRESH]\n",
    "        df_ranking_style.applymap(lambda value: \"color: darkgray;\", subset=(index_incomplete, df_ranking.columns.drop(\"algorithm\")))\n",
    "        # gray out algorithms to be hidden\n",
    "        index_hide = df_ranking.index[~df_ranking[\"algorithm\"].isin(select_show_algorithms.value)]\n",
    "        df_ranking_style.applymap(lambda value: \"color: darkgray;\", subset=(index_hide, df_ranking.columns))\n",
    "        # gray out not yet computed results\n",
    "        index_nan = df_ranking.index[df_ranking[M_REC].isna()]\n",
    "        df_ranking_style.applymap(lambda value: \"color: darkgray;\", subset=(index_nan, df_ranking.columns))\n",
    "        # format values\n",
    "        df_ranking_style.format(\"{:.2%}\", na_rep=\"N/A\", subset=M_REC)\n",
    "        df_ranking_style.format(precision=0, na_rep=\"N/A\", subset=[M_RANK, M_MIS, M_MEA, M_MEA_THRESH])\n",
    "        df_ranking_style.format(precision=2, na_rep=\"N/A\", subset=[M_REG_AVG, M_REG_MAX])\n",
    "        \n",
    "        if \"_ranking_style\" not in results:\n",
    "            results[\"_rankings_style\"] = {}\n",
    "        results[\"_rankings_style\"][object] = df_ranking_style\n",
    "\n",
    "        # plot object\n",
    "        plt_object.plot_object(object)\n",
    "        \n",
    "        # plot relative number of total observations\n",
    "        max_n_measurements = np.max([result.n_measurements for result in results_obj.values()], initial=10)\n",
    "        plt_total.axis.set_xlim([0, max_n_measurements + 2])\n",
    "        plt_total.axis.set_ylim([0, 1.2])\n",
    "        plt_total.static(\"n_max\", lambda: plt_total.axis.axhline(1, color=\"red\", linestyle=\"--\", linewidth=1))\n",
    "        plt_total.static(\"n_thresh\", lambda: plt_total.axis.axhline(REC_THRESH, color=\"red\", alpha=0.25, linestyle=\"--\", linewidth=1))\n",
    "        for algorithm in selected[\"algorithms\"]:\n",
    "            x = results_obj[algorithm].rounds if algorithm in results_obj else []\n",
    "            y = results_obj[algorithm].n_total_rel if algorithm in results_obj else []\n",
    "            plt_total.dynamic_plot(\"n_total:\" + algorithm, x, y, marker=\"o\", markersize=4, color=ALGORITHM_COLORS[algorithm], visible=algorithm in select_show_algorithms.value)\n",
    "        \n",
    "        # plot absolute number of marginal observations\n",
    "        max_n_marginal = np.max([np.max(result.n_marginal) for result in results_obj.values()], initial=10)\n",
    "        plt_marginal.axis.set_xlim([0, max_n_measurements + 2])\n",
    "        plt_marginal.axis.set_ylim([0, max_n_marginal * 1.2])\n",
    "        for algorithm in selected[\"algorithms\"]:\n",
    "            x = results_obj[algorithm].rounds if algorithm in results_obj else []\n",
    "            y = results_obj[algorithm].n_marginal if algorithm in results_obj else []\n",
    "            plt_marginal.dynamic_plot(\"n_marginal:\" + algorithm, x, y, marker=\"o\", markersize=4, color=ALGORITHM_COLORS[algorithm], visible=algorithm in select_show_algorithms.value)\n",
    "        \n",
    "        # plot regret\n",
    "        max_regret = np.max([np.max(result.regret) for result in results_obj.values()], initial=10)\n",
    "        plt_regret.axis.set_xlim([0, max_n_measurements + 2])\n",
    "        plt_regret.axis.set_ylim([-2, max_regret * 1.2])\n",
    "        for algorithm in selected[\"algorithms\"]:\n",
    "            x = results_obj[algorithm].rounds if algorithm in results_obj else []\n",
    "            y = results_obj[algorithm].regret if algorithm in results_obj else []\n",
    "            plt_regret.dynamic_plot(\"regret:\" + algorithm, x, y, marker=\"o\", markersize=4, color=ALGORITHM_COLORS[algorithm], visible=algorithm in select_show_algorithms.value)\n",
    "        \n",
    "        with profiler.cm(\"display\"):\n",
    "            with out_obj[\"ranking\"]:\n",
    "                display(df_ranking_style, clear=True)\n",
    "            plt_object.display(out_obj[\"fig_object\"])\n",
    "            plt_total.display(out_obj[\"fig_total\"])\n",
    "            plt_marginal.display(out_obj[\"fig_marginal\"])\n",
    "            plt_regret.display(out_obj[\"fig_regret\"])\n",
    "    \n",
    "    def plot_object_preview(obj):\n",
    "        with profiler.cm(\"plotting\"):\n",
    "            plt_object.plot_object(obj)\n",
    "        with profiler.cm(\"display\"):\n",
    "            plt_object.display(out[\"fig_object\"])\n",
    "    \n",
    "    ### DEFINE WIDGET HANDLERS ###\n",
    "\n",
    "    def observe_object_selector(*args):\n",
    "        refresh_buttons()\n",
    "        plot_object_preview(object_selector.value)\n",
    "\n",
    "    def add_object(*args):\n",
    "        select_objects.options += (object_selector.value,)\n",
    "        refresh_buttons()\n",
    "\n",
    "    def remove_object(*args):\n",
    "        select_objects.options = list(filter(lambda option: option not in select_objects.value, select_objects.options))\n",
    "        refresh_buttons()\n",
    "    \n",
    "    def move_object_up(*args):\n",
    "        i = select_objects.index[0]\n",
    "        options = list(select_objects.options)\n",
    "        options[i], options[i-1] = options[i-1], options[i]\n",
    "        select_objects.options = tuple(options)\n",
    "        select_objects.index = [i-1]\n",
    "        refresh_buttons()\n",
    "    \n",
    "    def move_object_down(*args):\n",
    "        i = select_objects.index[0]\n",
    "        options = list(select_objects.options)\n",
    "        options[i], options[i+1] = options[i+1], options[i]\n",
    "        select_objects.options = tuple(options)\n",
    "        select_objects.index = [i+1]\n",
    "        refresh_buttons()\n",
    "    \n",
    "    def observe_select_objects(change):\n",
    "        refresh_buttons()\n",
    "        if len(change[\"new\"]) == 1:\n",
    "            plot_object_preview(change[\"new\"][0])\n",
    "        elif len(change[\"new\"]) - len(change[\"old\"]) == 1:\n",
    "            plot_object_preview(set(change[\"new\"]).difference(set(change[\"old\"])).pop())\n",
    "    \n",
    "    def observe_select_algorithms(*args):\n",
    "        refresh_buttons()\n",
    "        # enforce selection of TRUE_ALGORITHM\n",
    "        if TRUE_ALGORITHM not in select_algorithms.value:\n",
    "            select_algorithms.unobserve(observe_select_algorithms, names=\"value\")\n",
    "            select_algorithms.index = sorted(select_algorithms.index + (select_algorithms.options.index(TRUE_ALGORITHM),))\n",
    "            select_algorithms.observe(observe_select_algorithms, names=\"value\")\n",
    "\n",
    "    def refresh_buttons(*args):\n",
    "        button_obj_add.disabled = object_selector.value in select_objects.options\n",
    "        button_obj_remove.disabled = len(select_objects.value) == 0\n",
    "        button_obj_up.disabled = len(select_objects.index) != 1 or select_objects.index[0] == 0\n",
    "        button_obj_down.disabled = len(select_objects.index) != 1 or select_objects.index[0] == len(select_objects.options) - 1\n",
    "        if button_start_init.description == \"init\":\n",
    "            button_start_init.disabled = len(select_objects.value) == 0 or len(select_algorithms.value) == 0\n",
    "\n",
    "    def setup(objects, algorithms, kernel):\n",
    "        # initialize global variables\n",
    "        nonlocal selected\n",
    "        selected = dict(\n",
    "            objects=objects,\n",
    "            algorithms=algorithms,\n",
    "            kernel=kernel,\n",
    "        )\n",
    "        nonlocal results\n",
    "        results = {object: {} for object in objects}\n",
    "        nonlocal plotters\n",
    "        plotters = {object: {} for object in objects}\n",
    "        for object, plts in plotters.items():\n",
    "            plts[\"plt_object\"] = SimulationPlotter(mode=\"real\", figsize=1.5, undecorated=True)\n",
    "            plts[\"plt_total\"] = SimulationPlotter(figsize=(7, 3), title=\"Reconstruction Progress ({})\".format(object), xlabel=\"rounds\", ylabel=\"progress\")\n",
    "            plts[\"plt_marginal\"] = SimulationPlotter(figsize=(7, 3), title=\"Marginal Observations ({})\".format(object), xlabel=\"rounds\", ylabel=\"#points\")\n",
    "            plts[\"plt_regret\"] = SimulationPlotter(figsize=(7, 3), title=\"Individual Regret ({})\".format(object), xlabel=\"rounds\", ylabel=\"#points\")\n",
    "            plts[\"out\"] = build_widget_outputs([\"fig_object\", \"ranking\", \"fig_total\", \"fig_marginal\", \"fig_regret\"])\n",
    "        \n",
    "        # initialize widgets\n",
    "        tab_containers = [tab_results.children[0]]\n",
    "        # tab_titles = [tab_results.titles[0]]\n",
    "        tab_titles = [tab_results.get_title(0)] # FIX for compatibility with ipywidgets 7.*\n",
    "        for object in objects:\n",
    "            out = plotters[object][\"out\"]\n",
    "            tab_containers.append(widgets.VBox([\n",
    "                widgets.HBox([out[\"ranking\"], out[\"fig_object\"]]),\n",
    "                out[\"fig_total\"],\n",
    "                out[\"fig_marginal\"],\n",
    "                out[\"fig_regret\"],\n",
    "            ]))\n",
    "            tab_titles.append(str(object))\n",
    "        tab_results.children = tab_containers\n",
    "        # tab_results.titles = tab_titles\n",
    "        for i, title in enumerate(tab_titles):\n",
    "            tab_results.set_title(i, title) # FIX for compatibility with ipywidgets 7.*\n",
    "        select_show_algorithms.unobserve(refresh_plot, names=\"value\")\n",
    "        select_show_algorithms.options = algorithms\n",
    "        select_show_algorithms.value = algorithms\n",
    "        select_show_algorithms.observe(refresh_plot, names=\"value\")\n",
    "\n",
    "    def init_or_start(*args):\n",
    "        profiler.reset()\n",
    "     \n",
    "        # initialize experiments\n",
    "        if button_start_init.description == \"init\":\n",
    "            button_start_init.description = \"start\"\n",
    "            button_start_init.disabled = False\n",
    "            button_reset.disabled = False\n",
    "            button_save.disabled = True\n",
    "            button_load.disabled = True\n",
    "\n",
    "            setup(\n",
    "                objects=select_objects.value,\n",
    "                algorithms=select_algorithms.value,\n",
    "                kernel=kernel_selector.value,\n",
    "            )\n",
    "            plot_results()\n",
    "        \n",
    "        # start experiments\n",
    "        elif button_start_init.description == \"start\":\n",
    "            button_start_init.disabled = True\n",
    "            button_reset.disabled = True\n",
    "            button_save.disabled = True\n",
    "            button_load.disabled = True\n",
    "            compute()\n",
    "            button_start_init.description = \"init\"\n",
    "            button_start_init.disabled = len(select_objects.value) == 0 or len(select_algorithms.value) == 0\n",
    "            button_reset.disabled = True\n",
    "            button_save.disabled = False\n",
    "            button_load.disabled = False\n",
    "    \n",
    "    def reset(*args):\n",
    "        profiler.reset()\n",
    "\n",
    "        button_start_init.description = \"init\"\n",
    "        button_start_init.disabled = len(select_objects.value) == 0 or len(select_algorithms.value) == 0\n",
    "        button_reset.disabled = True\n",
    "        button_save.disabled = True\n",
    "        button_load.disabled = False\n",
    "\n",
    "        # reset global variables (before resetting widgets)\n",
    "        nonlocal selected\n",
    "        selected = dict(objects=[], algorithms=[], kernel=None)\n",
    "        nonlocal results\n",
    "        results = {}\n",
    "        nonlocal plotters\n",
    "        plotters = {}\n",
    "        \n",
    "        # reset widgets\n",
    "        tab_results.children = [tab_results.children[0]]\n",
    "        select_show_algorithms.unobserve(refresh_plot, names=\"value\")\n",
    "        select_show_algorithms.options = []\n",
    "        select_show_algorithms.value = []\n",
    "        select_show_algorithms.observe(refresh_plot, names=\"value\")\n",
    "        plot_results()\n",
    "            \n",
    "    def save_results(*args):\n",
    "        filetag = \"_\" + textfield_filetag.value if textfield_filetag.value != \"\" else \"\"\n",
    "        filename = \"results{}_{}\".format(filetag, datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "        filepath = os.path.join(OUTPUT, filename)\n",
    "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "\n",
    "        results_saved = {str(object): {\"object\": object.to_json(), \"result\": result} for object, result in results.items() if not str(object).startswith(\"_\")}\n",
    "        # save results as json\n",
    "        with open(\"{}.json\".format(filepath), \"w\") as file:\n",
    "            json.dump(results_saved, file, indent=2, default=build_json_encoder([\n",
    "                (SimulationResults, lambda results: results.to_dict()),\n",
    "            ]))\n",
    "            print(\"Results saved to \\\"{}.json\\\".\".format(filepath))\n",
    "        \n",
    "        df_summary_style = results[\"_summary_style\"]\n",
    "        # save summary as txt\n",
    "        with open(\"{}.txt\".format(filepath), \"w\") as file:\n",
    "            df_summary_style.to_string(file)\n",
    "            print(\"Summary saved to \\\"{}.txt\\\".\".format(filepath))\n",
    "        # save summary as html\n",
    "        with open(\"{}.html\".format(filepath), \"w\") as file:\n",
    "            df_summary_style.to_html(file)\n",
    "            print(\"Summary saved to \\\"{}.html\\\".\".format(filepath))\n",
    "        \n",
    "        # append summary to html\n",
    "        filepath_summary = os.path.join(OUTPUT, textfield_filename_summary.value)\n",
    "        with open(\"{}.html\".format(filepath_summary), \"a\") as file:\n",
    "            file.write(\"\\n\\n\\n<h3>{}</h3>\\n\".format(filename))\n",
    "            df_summary_style.to_html(file)\n",
    "            print(\"Summary appended to \\\"{}.html\\\".\".format(filepath_summary))\n",
    "    \n",
    "    def load_results(*args):\n",
    "        profiler.reset()\n",
    "\n",
    "        button_load.disabled = True\n",
    "        button_save.disabled = True\n",
    "        try:\n",
    "            with profiler.cm(\"computation\"):\n",
    "                nonlocal results\n",
    "                filepath = os.path.join(OUTPUT, textfield_filename.value)\n",
    "                with open(\"{}.json\".format(filepath), \"r\") as file:\n",
    "                    results_dict = json.load(file)\n",
    "                    setup([Object.from_json(data[\"object\"]) for data in results_dict.values()], list(results_dict[list(results_dict.keys())[0]][\"result\"].keys()), None)\n",
    "                    for _, data in results_dict.items():\n",
    "                        object = Object.from_json(data[\"object\"])\n",
    "                        for algorithm, result in data[\"result\"].items():\n",
    "                            results[object][algorithm] = SimulationResults.from_dict(result)\n",
    "                    plot_results()\n",
    "        finally:\n",
    "            button_reset.disabled = False\n",
    "            button_save.disabled = False\n",
    "            button_load.disabled = False\n",
    "\n",
    "    def refresh_plot(*args):\n",
    "        profiler.reset()\n",
    "        plot_results()\n",
    "    \n",
    "    ### INITIALIZATION ###\n",
    "    \n",
    "    profiler = Profiler()\n",
    "    with profiler.cm(\"initialization\"):\n",
    "        # define global variables\n",
    "        selected = dict(objects=[], algorithms=[], kernel=None) # store snapshot of configurations after start\n",
    "        results = {}\n",
    "        plotters = {}\n",
    "\n",
    "        # initialize plotters\n",
    "        plt_object = SimulationPlotter(mode=\"real\", figsize=1, undecorated=True)\n",
    "\n",
    "        ### SETUP WIDGETS ###\n",
    "\n",
    "        # define layouts\n",
    "        layout_select = dict(flex=\"1 1 auto\", max_width=\"350px\", max_height=\"300px\", align_items=\"stretch\")\n",
    "        layout_button = dict(width=\"25%\")\n",
    "\n",
    "        # define output widgets\n",
    "        out = build_widget_outputs([\"fig_object\", \"progressbar\", \"tab_summary\", \"log\"])\n",
    "\n",
    "        # define widgets for simulation setup\n",
    "        object_selector = ObjectSelector()\n",
    "        object_selector.observe(observe_object_selector, names=\"value\")\n",
    "        button_obj_add = widgets.Button(description=\"+\", layout=layout_button)\n",
    "        button_obj_add.on_click(add_object)\n",
    "        button_obj_remove = widgets.Button(description=\"-\", layout=layout_button)\n",
    "        button_obj_remove.on_click(remove_object)\n",
    "        button_obj_up = widgets.Button(description=\"▲\", layout=layout_button)\n",
    "        button_obj_up.on_click(move_object_up)\n",
    "        button_obj_down = widgets.Button(description=\"▼\", layout=layout_button)\n",
    "        button_obj_down.on_click(move_object_down)\n",
    "        object_selector_and_buttons = widgets.VBox([\n",
    "            object_selector,\n",
    "            widgets.HBox([button_obj_add, button_obj_remove, button_obj_up, button_obj_down]),\n",
    "        ])\n",
    "        select_objects = widgets.SelectMultiple(description=\"objects\", layout=layout_select)\n",
    "        select_objects.observe(observe_select_objects, names=\"value\")\n",
    "        \n",
    "        kernel_selector = KernelSelector()\n",
    "        kernel_selector.observe(refresh_buttons, names=\"value\")\n",
    "        select_algorithms = widgets.SelectMultiple(options=ALGORITHMS, index=[1,4,6,8,10,12,13,15,17,18], description=\"algorithm\", layout=layout_select)\n",
    "        select_algorithms.observe(observe_select_algorithms, names=\"value\")\n",
    "        \n",
    "        button_start_init = widgets.Button(description=\"init\")\n",
    "        button_start_init.on_click(init_or_start)\n",
    "        button_reset = widgets.Button(description=\"reset\", disabled=True)\n",
    "        button_reset.on_click(reset)\n",
    "        \n",
    "        display(\n",
    "            widgets.HBox([object_selector_and_buttons, select_objects, out[\"fig_object\"]]),\n",
    "            widgets.HBox([kernel_selector, select_algorithms]),\n",
    "            widgets.HBox([button_start_init, button_reset]),\n",
    "        )\n",
    "        \n",
    "        # display widgets for results\n",
    "        select_show_algorithms = widgets.SelectMultiple(options=[], layout=dict(width=\"250px\", max_height=\"300px\", align_items=\"stretch\"))\n",
    "        select_show_algorithms.observe(refresh_plot, names=\"value\")\n",
    "\n",
    "        textfield_filename = widgets.Text(value=\"\", description=\"file\")\n",
    "        button_load = widgets.Button(description=\"load\")\n",
    "        button_load.on_click(load_results)\n",
    "        textfield_filetag = widgets.Text(value=\"\", description=\"file tag\")\n",
    "        textfield_filename_summary = widgets.Text(value=\"summary\", description=\"summary file\")\n",
    "        button_save = widgets.Button(description=\"save\", disabled=True)\n",
    "        button_save.on_click(save_results)\n",
    "        tab_results_summary = widgets.VBox([\n",
    "            out[\"tab_summary\"],\n",
    "            textfield_filename,\n",
    "            button_load,\n",
    "            textfield_filetag,\n",
    "            textfield_filename_summary,\n",
    "            button_save,\n",
    "        ])\n",
    "        # tab_results = widgets.Tab(children=[tab_results_summary], titles=[\"summary\"])\n",
    "        tab_results = widgets.Tab(children=[tab_results_summary])\n",
    "        tab_results.set_title(0, \"summary\") # FIX for compatibility with ipywidgets 7.*\n",
    "        \n",
    "        if ENV == COLAB:\n",
    "            output.disable_custom_widget_manager() # FIX\n",
    "        display(\n",
    "            out[\"progressbar\"],\n",
    "            widgets.HBox([select_show_algorithms, tab_results]),\n",
    "            out[\"log\"],\n",
    "        )\n",
    "        if ENV == COLAB:\n",
    "            output.enable_custom_widget_manager() # FIX\n",
    "\n",
    "        refresh_buttons()\n",
    "\n",
    "        # add some objects to select_objects\n",
    "        select_objects.options += (EllipseObject(),)\n",
    "        select_objects.options += (SquareObject(),)\n",
    "        select_objects.options += (FlowerObject(),)\n",
    "        for name in PolygonObject.polygon_names:\n",
    "            select_objects.options += (PolygonObject.build(name),)\n",
    "        select_objects.index = [4]\n",
    "    \n",
    "    plot_object_preview(object_selector.value)\n",
    "    plot_results()\n",
    "\n",
    "plt.close(\"all\")\n",
    "run_evaluation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "da4f1755d18dd94b06a22914d795f84f5c18221f3962a33deafaedf314972838"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
